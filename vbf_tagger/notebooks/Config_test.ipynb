{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cbc822-2730-4384-936d-42e23bd52179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from vbf_tagger.tools.evaluation import general as g\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7d6084-12a2-40aa-83a0-1c18dc0bda7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host:\n",
      "  name: manivald\n",
      "  project_dir: /home/norman/vbf-tagger\n",
      "  data_dir: /home/norman/vbf-tagger/vbf_tagger/data\n",
      "  tmp_dir: /home/norman/tmp\n",
      "  slurm:\n",
      "    queue:\n",
      "      preprocessing:\n",
      "        output_dir: /home/norman/VBF_preprocessing\n",
      "        partition: main\n",
      "        time: 06:00:00\n",
      "        cpus: 1\n",
      "        mem_map:\n",
      "          CEPC:\n",
      "            one_step: 25G\n",
      "            two_step: 25G\n",
      "          FCC:\n",
      "            one_step: 12G\n",
      "            two_step: 12G\n",
      "        mem: ${host.slurm.queue.preprocessing.mem_map[${dataset.name}][${preprocessing.data_type}]}\n",
      "dataset:\n",
      "  name: 22pre\n",
      "  input_dim: 1200\n",
      "  branches: null\n",
      "  tree_path: null\n",
      "  raw_input_dir: ${host.data_dir}/22pre/\n",
      "  data_dir: ${host.data_dir}/22pre/hh_vbf/preprocessed_filtered/\n",
      "  datasets:\n",
      "    vbf: ${host.data_dir}/hh_vbf/\n",
      "  train_dataset:\n",
      "  - vbf\n",
      "  test_dataset:\n",
      "  - vbf\n",
      "  train_dir: train\n",
      "  val_dir: val\n",
      "  test_dir: test\n",
      "models:\n",
      "  classification:\n",
      "    model:\n",
      "      _target_: vbf_tagger.models.LorentzNet.classification\n",
      "      name: classification\n",
      "      hyperparameters:\n",
      "        n_scalar: 4\n",
      "        n_hidden: 1\n",
      "        n_class: 16\n",
      "        dropout: 0\n",
      "        n_layers: 2\n",
      "        c_weight: 1\n",
      "        verbosity: 1\n",
      "        lr: 0.001\n",
      "      checkpoint:\n",
      "        model: null\n",
      "        losses: null\n",
      "datasets:\n",
      "  22pre:\n",
      "    name: 22pre\n",
      "    input_dim: 1200\n",
      "    branches: null\n",
      "    tree_path: null\n",
      "    raw_input_dir: ${host.data_dir}/22pre/\n",
      "    data_dir: ${host.data_dir}/22pre/hh_vbf/preprocessed_filtered/\n",
      "    datasets:\n",
      "      vbf: ${host.data_dir}/hh_vbf/\n",
      "    train_dataset:\n",
      "    - vbf\n",
      "    test_dataset:\n",
      "    - vbf\n",
      "    train_dir: train\n",
      "    val_dir: val\n",
      "    test_dir: test\n",
      "evaluation:\n",
      "  dataset:\n",
      "    num_evaluation_waveforms: 1000\n",
      "    results_output_dir: ${training.results_dir}/data\n",
      "  training:\n",
      "    eval_all: ${training.eval_all}\n",
      "training:\n",
      "  debug_run: false\n",
      "  type: classification\n",
      "  output_dir: null\n",
      "  output_dir_: ${training.output_dir}/${training.type}\n",
      "  models_dir: ${training.output_dir_}/models\n",
      "  log_dir: ${training.output_dir_}/logs\n",
      "  predictions_dir: ${training.output_dir_}/predictions\n",
      "  results_dir: ${training.output_dir_}/results\n",
      "  dataloader:\n",
      "    batch_sizes:\n",
      "      classification: 4096\n",
      "    batch_size: ${training.dataloader.batch_sizes[${training.type}]}\n",
      "    num_dataloader_workers: 1\n",
      "    prefetch_factor: 100\n",
      "  trainer:\n",
      "    max_epochs: 250\n",
      "  model_evaluation: false\n",
      "  eval_all: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"main\")\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a11e6f-580a-482a-8820-ed9235874a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vbf_tagger.tools.data.dataloaders import VBFDataModule\n",
    "from hydra import compose, initialize\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../config\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "258a8f75-05d5-4136-a62a-6179c068c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,048 waveforms/events/jets in the dataset.\n",
      "There are 2,048 waveforms/events/jets in the dataset.\n",
      "Returning tensors with shapes: torch.Size([1024, 11, 16]) torch.Size([1024, 4, 16]) torch.Size([1024, 1, 16]) torch.Size([1024, 16])\n",
      "cand_featuress: torch.Size([1, 11, 16])\n",
      "cand_kinematics: torch.Size([1, 4, 16])\n",
      "node_mask: torch.Size([1, 1, 16])\n",
      "targets: torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "datamodule = VBFDataModule(cfg=cfg, data_type=\"train\", debug_run=True)\n",
    "datamodule.setup(stage=\"fit\")\n",
    "\n",
    "batch = next(iter(datamodule.train_dataloader()))\n",
    "print(\"cand_featuress:\", batch[0].shape)\n",
    "print(\"cand_kinematics:\", batch[1].shape)\n",
    "print(\"node_mask:\", batch[2].shape)\n",
    "print(\"targets:\", batch[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341bbf0e-b12e-4c6b-8a49-75bcb83cafd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'vbf_tagger.models.LorentzNet.classification'>\n"
     ]
    }
   ],
   "source": [
    "from vbf_tagger.models.LorentzNet import classification\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f350d-e937-44be-bc27-af312e245be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
